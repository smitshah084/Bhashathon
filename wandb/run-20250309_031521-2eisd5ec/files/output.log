Training Progress:   0%|                                                                                                                          | 2/6200 [00:37<29:30:40, 17.14s/it]
ITER:  0
                                                                                                                                                                                      
iter 0: loss 10.9653, time 29244.42ms, mfu -100.00%

==================================================
PERFORMANCE METRICS (iter 0):
Training tokens/second: 56941.52
Testing tokens/second: 0.00
Parameter update time: 583.12ms (frequency: every 30 micro steps)
Data loading time: 1.43ms per batch
Train batch processing time: 954.79ms
Test batch processing time: 0.00ms
Estimated time to train on 9.1M tokens: 0h 2m 31s
==================================================

ITER:  1
iter 1: loss 10.9554, time 8123.64ms, mfu -100.00%

==================================================
PERFORMANCE METRICS (iter 1):
Training tokens/second: 56945.53
Testing tokens/second: 0.00
Parameter update time: 298.68ms (frequency: every 30 micro steps)
Data loading time: 1.35ms per batch
Train batch processing time: 612.07ms
Test batch processing time: 0.00ms
Estimated time to train on 9.1M tokens: 0h 2m 22s
==================================================

ITER:  2
iter 2: loss 10.9298, time 8660.44ms, mfu -100.00%

==================================================
PERFORMANCE METRICS (iter 2):
Training tokens/second: 56946.98
Testing tokens/second: 0.00
Parameter update time: 203.87ms (frequency: every 30 micro steps)
Data loading time: 1.33ms per batch
Train batch processing time: 497.84ms
Test batch processing time: 0.00ms
Estimated time to train on 9.1M tokens: 0h 2m 13s
==================================================

ITER:  3
iter 3: loss 10.9049, time 8660.57ms, mfu -100.00%

==================================================
PERFORMANCE METRICS (iter 3):
Training tokens/second: 56944.18
Testing tokens/second: 0.00
Parameter update time: 156.46ms (frequency: every 30 micro steps)
Data loading time: 1.31ms per batch
Train batch processing time: 271.19ms
Test batch processing time: 0.00ms
Estimated time to train on 9.1M tokens: 0h 2m 5s
==================================================

ITER:  4
iter 4: loss 10.8716, time 8661.55ms, mfu -100.00%

==================================================
PERFORMANCE METRICS (iter 4):
Training tokens/second: 56936.52
Testing tokens/second: 0.00
Parameter update time: 128.02ms (frequency: every 30 micro steps)
Data loading time: 1.32ms per batch
Train batch processing time: 271.20ms
Test batch processing time: 0.00ms
Estimated time to train on 9.1M tokens: 0h 1m 56s
==================================================

ITER:  5
iter 5: loss 10.8250, time 8660.06ms, mfu 15.55%

==================================================
PERFORMANCE METRICS (iter 5):
Training tokens/second: 56949.12
Testing tokens/second: 0.00
Parameter update time: 109.06ms (frequency: every 30 micro steps)
Data loading time: 1.31ms per batch
Train batch processing time: 271.19ms
Test batch processing time: 0.00ms
Estimated time to train on 9.1M tokens: 0h 1m 48s
==================================================

ITER:  6
iter 6: loss 10.7651, time 8660.99ms, mfu 15.55%

==================================================
PERFORMANCE METRICS (iter 6):
Training tokens/second: 56951.33
Testing tokens/second: 0.00
Parameter update time: 95.52ms (frequency: every 30 micro steps)
Data loading time: 1.30ms per batch
Train batch processing time: 271.20ms
Test batch processing time: 0.00ms
Estimated time to train on 9.1M tokens: 0h 1m 39s
==================================================

ITER:  7
iter 7: loss 10.7136, time 8659.59ms, mfu 15.55%

==================================================
PERFORMANCE METRICS (iter 7):
Training tokens/second: 56951.81
Testing tokens/second: 0.00
Parameter update time: 85.36ms (frequency: every 30 micro steps)
Data loading time: 1.31ms per batch
Train batch processing time: 271.16ms
Test batch processing time: 0.00ms
Estimated time to train on 9.1M tokens: 0h 1m 30s
==================================================

ITER:  8
saving checkpoint to out
